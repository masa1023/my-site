---
title: '5-Day Gen AI Intensive Course with Google 参加レポート'
description: 'Exploring how ScholarAgent uses Generative AI, RAG, and LangGraph to make complex machine learning research papers more accessible and interactive for learners.'
date: '2025-04-22'
tags: ['Generative AI', 'AI Agents', 'RAG']
---

2025年3月31日から4月4日まで開催された「5-Day Gen AI Intensive Course with Google」に参加し、生成 AI の最前線とその応用について、大きな学びを得ることができました！

本記事では、5日間のコース内容を日ごとに振り返りながら、そこで得た学びについて、まとめたいと思います。

## 「5-Day Gen AI Intensive Course with Google」とは？

「5-Day Gen AI Intensive Course with Google」とは、Google主催の生成AIに特化した5日間の短期集中オンライン講義です。
今回は世界中から約25万人が参加したとのことです！すごい！

特徴

- AI領域の第一線で活躍するGoogleの機械学習エンジニア・研究者がコンテンツを作成・監修
- Googleの社員10名弱がその日のテーマについてディスカッションしたり質問にこたえるYouTube LIVEが5日間毎日開催
- 期間中DiscordでGoogle社員や他の参加者とコミュニケーションが可能
- Capstone Projectと呼ばれる総仕上げプロジェクトに取り組めばKaggleバッジと修了証がもらえる

一日の流れ

1. 5日間毎日、その日のテーマについて解説した50ページ以上のホワイトペーパー(PDF)が届く
1. PDFを元にNotebookLMで作成されたPodcast(約30分)をYouTube上で聴きながらホワイトペーパーを読む
1. その日のテーマの実践としてKaggle Notebookでドキュメントを読みつつコードを実行
1. 日本時間深夜3時頃にYouTube LIVE開始。翌朝アーカイブを視聴(約1時間)

取り組んでみての感想

一日のPDFのボリュームがかなりあり、PDFとNotebookが複数ある日もあったのでなかなか仕事と並行して進めるのはなかなか大変でした！しかも全コンテンツ英語！

その上内容も本格的で、「LLMの基礎的な仕組みとプロンプトエンジニアリングの応用を学ぶくらいでしょ？」って思ってたらプログラミングや機械学習の基礎知識を前提とした開発者向けのかなり技術に踏み込んだコンテンツになっていました。

英語+新しい技術領域なので初日にどっと疲れ、これは三日坊主コースかなと思いましたが、最先端の知識を学んでいくうちにどんどん楽しくなってきて、気づいたら5日間のコースを完走していました！

Kaggle Notebook では事前に用意されたコードを実行していくだけでよく、その日学んだことの理解が定着しているか、実践に繋がっているか怪しかったので、コース全体の総復習に最適だと思い Capstone Project にも取り組みました。

以下に5日間で学んだ内容についてざっくりまとめます。  
ほとんどのコンテンツがオンラインで公開されており、誰でも閲覧可能なのでそれらのリソースへのリンクも一緒にまとめていきます。

## Day 1: LLMの基礎とプロンプトエンジニアリング

### 学習リソース

- Whitepaper:
  - https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation
  - https://www.kaggle.com/whitepaper-prompt-engineering
- Podcast:
  - https://www.youtube.com/watch?v=Na3O4Pkbp-U
  - https://www.youtube.com/watch?v=CFtX0ZyLSAY
- Kaggle Notebook
  - https://www.kaggle.com/code/markishere/day-1-prompting
  - https://www.kaggle.com/code/markishere/day-1-evaluation-and-structured-output
- YouTube Live: https://www.youtube.com/watch?v=WpIfAeCIFc0

### 大規模言語モデル（LLM）

初日はLLMの基礎概念と使用されている技術の解説から始まりました。

LLMの中核技術である**Transformerアーキテクチャ** や**Attention**の仕組み、データの入力処理（トークン化、埋め込み、位置エンコーディングなど）、およびその進化の歴史（GPT、BERT、Geminiなど多様なモデルファミリー） についての詳細な解説がありました。

資料では、モデルの**ファインチューニング手法**（SFT、RLHF、PEFTなど） や、望む出力を得るための**プロンプトエンジニアリング**（ゼロショット、Fewショット、Chain-of-Thoughtなど） やサンプリング技術 についても説明がありました。

また、推論の**高速化技術**（量子化、投機的デコーディングなど） や、テキスト生成、コード、翻訳、要約、質疑応答、マルチモーダル応用など、LLMの多様な応用例 も紹介されています。

### プロンプトエンジニアリング

初日の2つ目のトピックとして、LLM から期待通りの出力を得るために不可欠な **プロンプトエンジニアリング** が取り上げられました。

ChatGPTやGemini のようなチャットボットとの対話は簡単なプロンプトで行えますが、Google AI Studio や API 経由でモデルを利用することで、temperature、Top-K/Top-P、Max Token Limit などのパラメータをより細かく制御できることを学びました。

具体的なプロンプトエンジニアリングのテクニックとして

- Zero-shot Prompting：タスクの説明のみを与えるだけの最もシンプルな手法
- System Prompting：出力形式にJSONを指定するなど、モデルに追加のコンテキストや指示を与える
- Few-shot Prompting：モデルにタスクの実行方法を示すために、プロンプト内に少数の例を含める手法
- Chain-of-Thought (CoT) Prompting：複雑な問題に対して、一連の中間的な推論ステップを促す
- ReAct (Reasoning and Acting)：推論ステップと外部ツールへのアクセスなどのアクションを組み合わせる
- Automatic Prompt Engineering (APE)：プロンプトの生成と評価を自動化する

などの手法やプロンプトエンジニアリングのベストプラクティスについて学びました。

## Day 2:

- Whitepaper: https://www.kaggle.com/whitepaper-embeddings-and-vector-stores
- Podcast: https://www.youtube.com/watch?v=xCAVsst6WJ8
- Kaggle Notebook:
  - https://www.kaggle.com/code/markishere/day-2-document-q-a-with-rag
  - https://www.kaggle.com/code/markishere/day-2-embeddings-and-similarity-scores
  - https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras
- Day 2　YouTube Live: https://www.youtube.com/watch?v=AjpjCHdIINU

「Embeddings & Vector Stores」の資料は、様々な種類のデータを**統一されたベクトル表現（エンベディング）**に変換し、それらを効率的に管理・検索するための技術について、包括的に解説しています。

まず、**エンベディング**とは、テキスト、画像、音声などの実世界のデータを**低次元の数値ベクトル**に変換したもので、ベクトル空間上での距離が元のデータの**意味的な類似性**を反映するように設計されています。これにより、大規模なデータの効率的な処理と格納、そして意味に基づいた比較や検索が可能になります。エンベディングの品質は、関連性の高いアイテムをどれだけ正確に検索できるかで評価され、Precision@K、Recall@K、nDCGといった指標が用いられます。

資料では、以下のようないくつかの主要なエンベディングタイプが紹介されています:

- **テキストエンベディング**: 単語エンベディング（Word2Vec, GloVeなど、文脈に依存しない場合が多い）とドキュメントエンベディング（BERTのようなTransformerベースのモデル、Doc2Vecなど、文脈を考慮する）があります。テキストをトークン化し、それを数値ベクトルに変換するプロセスも説明されています。
- **画像およびマルチモーダルエンベディング**: 画像単体のエンベディングや、テキストと画像を共通の空間にマッピングするエンベディングがあります。
- **構造化データエンベディング**: テーブルの各行などをベクトル化するもので、異常検知やレコメンデーションなどに利用されます。
- **グラフエンベディング**: グラフ構造（ノードとエッジ）を持つデータをベクトル化し、ノード自体の情報だけでなく、その関係性や関連性も捉えます。

エンベディングの学習には、デュアルエンコーダー構造や対照学習損失（contrastive loss）が一般的に用いられ、ファウンデーションモデルからのファインチューニングも行われます。

次に、生成されたエンベディングを効率的に検索するための**ベクトル検索**について説明されています。これは、厳密なキーワード一致ではなく、ベクトル間の類似性（ユークリッド距離、コサイン類似度など）に基づいて検索を行うものです。大規模データセットでは、線形検索は非効率なため、**近似最近傍探索（ANN）**アルゴリズムが不可欠です。資料では、LSH、ツリーベース（Kd-tree, Ball-tree）、HNSW、Googleが開発したScaNNといった主要なANNアルゴリズムが紹介されています。

これらのエンベディングとベクトル検索を大規模かつ本番環境で管理するために**ベクトルデータベース**が使用されます。ベクトルデータベースは、ベクトル、関連するメタデータ、元のコンテンツを格納し、ANNアルゴリズムによる高速検索を可能にします。Vertex AI Vector Searchのようなマネージドサービスや、Weaviate、ChromaDBなどのオープンソースの選択肢が挙げられています。運用上の考慮事項として、エンベディングの更新管理の難しさ、リテラル情報や専門用語に対するハイブリッド検索の必要性、ワークロードに応じたデータベースの選択などが述べられています。

最後に、エンベディングとベクトルデータベースの**応用例**が示されています。特に重要なのが**Retrieval Augmented Generation (RAG)**であり、エンベディング検索で取得した関連情報をLLMへのプロンプトに含めることで、LLMの回答の精度を高め、ハルシネーション（偽情報の生成）を抑制し、情報の出典を提供できるようになります。その他の応用には、検索、レコメンデーションシステム、異常検知、分類、リランキングなどがあります。

## Day 4: LLM のファインチューニングと運用化

4日目は、**大規模言語モデルのファインチューニング** と **運用化の初期段階** という重要な側面に焦点を当てました。プロンプトエンジニアリングだけでは最適な結果が得られないユースケースに対して、モデルを適応させる必要性を学びました。Vertex AI は、さまざまな技術をサポートする、LLM のトレーニングとチューニングのための包括的なプラットフォームを提供しています।

**教師ありファインチューニング（SFT: Supervised Fine-Tuning)** は、特定のドメイン固有のデータセット内のラベル付きの例を使用してモデルを適応させる手法であり、少数の例でも効果的であることを学びました。人間のフィードバックを用いた強化学習（RLHF: Reinforcement Learning from Human Feedback） は、モデルの出力を人間の好みに合わせるための方法です。さらに、**LoRA (Low-Rank Adaptation)**、**ソフトプロンプティング**、**蒸留** などのパラメータ効率的なチューニング技術、特に大規模な教師モデルから小さなタスク固有の生徒モデルに知識を転送する **ステップバイステップ蒸留** についても学びました。

運用化の観点からは、ML ワークフローのデプロイメント、管理、スケーリングを簡素化および自動化するサービスである **Vertex Pipelines** が紹介されました。特にチャットボットのような動的なアプリケーションにおける **継続的なチューニング** の重要性、そしてコストと進化する入力データを考慮する必要性についても触れました。

## Day 5: インテリジェントエージェントの構築と責任ある AI

最終日は、**Gen AI エージェントの構築** と **責任ある AI** の重要な考慮事項に焦点が当てられました。エージェントは、リアルタイムの情報にアクセスし、現実世界の行動を自律的に実行するためにツールを使用することで、言語モデルの能力を拡張するものであることを学びました。これには、推論、論理、そして外部情報へのアクセスが組み合わされています。

**ツール** はエージェントの「外界への鍵」として機能し、**エクステンション**、**関数**、**データストア** などが含まれます。**Vertex AI Agent Builder** は、さまざまなデータソースに対して Google 品質の検索を迅速にセットアップし、**Retrieval Augmented Generation (RAG)** 機能を提供することで、Gen AI アプリケーションとエージェントの構築を迅速化する製品スイートとして紹介されました。**Vertex AI Search** は、Google 検索技術を基盤とする、すぐに使用できるフルマネージドの検索および RAG プロバイダーです。

最後に、**責任ある AI** の重要な側面について議論しました。Vertex AI の **引用チェッカー** は、情報源の適切な帰属を保証します。AI によって生成された画像を識別するための SynthID を用いた **ウォーターマーキング** や、不公平または不適切な出力を軽減するための **コンテンツモデレーションおよびバイアス検出ツール** についても学びました。データ、調整済みモデル、そしてコードのライフサイクル全体にわたる **ガバナンス** の重要性も強調されました。

## キャップストーンプロジェクト

コースの集大成として、**キャップストーンプロジェクト** が課されました。これは、コースで学んだことを実際のユースケースに適用し、Kaggle Notebook で提出する機会です。

プロジェクトの概要は以下の通りです:

- **目標:** コースで学んだ生成 AI の能力を少なくとも3つ以上デモンストレーションする。
- **形式:** Kaggle Notebook でコードを提出し、任意でブログ記事と YouTube 動画を追加できる。
- **テーマ:** ユースケースは自由であり、創造的で現実世界の問題解決を目指すことが推奨される。
- **評価:** Notebook のコンパイル性、使用した Gen AI 能力の数、ドキュメントの質、ユースケースの革新性などが評価される。ブログ記事と YouTube 動画はボーナスポイントの対象となる。
- **提出期限:** 2025年4月20日。

私は、このキャップストーンプロジェクトを通じて、コースで学んだプロンプトエンジニアリング、RAG、そしてテキスト生成モデルの活用に取り組みました。具体的なユースケースについては、別の機会にブログ記事として公開したいと考えています。

## 結論

5日間の「Gen AI Intensive Course with Google」は、生成 AI の世界への深く貴重な探求の旅でした。LLM の基本原理の理解から、プロンプトエンジニアリング技術の習得、Vertex AI を活用したモデルのデプロイメント、ファインチューニング、そしてインテリジェントエージェントの構築まで、幅広い知識と実践的な経験を得ることができました。責任ある AI の実践に関する強調は、この急速に進歩する分野における倫理的考慮事項の重要性を再認識させてくれました。このコースで得た知識と経験を活かし、責任を持って効果的にこれらの強力な技術を活用していきたいと思います。
